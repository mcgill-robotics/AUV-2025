{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MAQ76bSTy48-",
        "COpq9wZczt1G"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies, set up folder structure, import necessary librairies, generate data.yaml file"
      ],
      "metadata": {
        "id": "MAQ76bSTy48-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I2wYwdPAyklw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79eabbdf-23a4-4ac2-9802-8f1cd5a1fd7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.8/dist-packages (1.2.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from albumentations) (6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.22.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (4.7.0.68)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.2.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (3.5.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (4.38.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.8/dist-packages (8.0.47)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (2.11.2)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (4.6.0.66)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (1.13.1+cu116)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (6.0)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (4.64.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from ultralytics) (5.4.8)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (1.7.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (0.11.2)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (3.5.3)\n",
            "Requirement already satisfied: certifi>=2022.12.7 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (2022.12.7)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (0.14.1+cu116)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.8/dist-packages (from ultralytics) (2.25.1)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.8/dist-packages (from ultralytics) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.38.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->ultralytics) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->ultralytics) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->ultralytics) (4.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->ultralytics) (0.38.4)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->ultralytics) (3.19.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->ultralytics) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->ultralytics) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->ultralytics) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->ultralytics) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->ultralytics) (1.51.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->ultralytics) (2.16.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->ultralytics) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->ultralytics) (1.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->ultralytics) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->ultralytics) (3.2.2)\n",
            "mkdir: cannot create directory â€˜dataâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmentedâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/rawâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/trainâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/testâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/valâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/train/imagesâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/test/imagesâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/val/imagesâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/train/labelsâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/test/labelsâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/val/labelsâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/raw/imagesâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/raw/labelsâ€™: File exists\n",
            "rm: cannot remove 'sample_data': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations\n",
        "!pip install opencv-python\n",
        "!pip install ultralytics\n",
        "!mkdir data\n",
        "!mkdir data/augmented\n",
        "!mkdir data/raw\n",
        "!mkdir data/augmented/train\n",
        "!mkdir data/augmented/test\n",
        "!mkdir data/augmented/val\n",
        "!mkdir data/augmented/train/images\n",
        "!mkdir data/augmented/test/images\n",
        "!mkdir data/augmented/val/images\n",
        "!mkdir data/augmented/train/labels\n",
        "!mkdir data/augmented/test/labels\n",
        "!mkdir data/augmented/val/labels\n",
        "!mkdir data/raw/images\n",
        "!mkdir data/raw/labels\n",
        "!rm -r sample_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "V3-T5zOB0sEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "342c333f-3ad3-49ee-b3cf-9048545843c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('data.yaml', 'w+') as f:\n",
        "    f.write(\"train: /content/data/augmented/train/images\\n\")\n",
        "    f.write(\"test: /content/data/augmented/test/images\\n\")\n",
        "    f.write(\"val: /content/data/augmented/val/images\\n\")\n",
        "    f.write(\"nc: 1\\n\")\n",
        "    f.write('names: [\"Lane Marker\"]')"
      ],
      "metadata": {
        "id": "N0SHMX1C2ZuL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augment data in /raw folder, put augmented dataset in /augmented folder"
      ],
      "metadata": {
        "id": "COpq9wZczt1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define individual augmentation functions and image file input/ouput helper functions. Each augmentation is a function that expects a list of (image, label) tuples, and returns the original tuples as well as all augmented versions of each (image, label) tuple in a larger list."
      ],
      "metadata": {
        "id": "aHa1-UEe0FuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#given a list of samples, make two copies of each sample that are darker/brighter to simulate differently lit environments\n",
        "def brightnessAugment(samples):\n",
        "    out = []\n",
        "    for sample in samples:\n",
        "        image, label = sample\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=(1.5, 1.5), contrast=0, saturation=0, hue=0, always_apply=True) ])\n",
        "        bright_img = transform(image=image)[\"image\"]\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=(0.5, 0.5), contrast=0, saturation=0, hue=0, always_apply=True) ])\n",
        "        dark_img = transform(image=image)[\"image\"]\n",
        "        out.append((bright_img, label))\n",
        "        out.append((dark_img, label))\n",
        "    samples.extend(out)\n",
        "    del out\n",
        "    del transform\n",
        "    del sample\n",
        "    return samples\n",
        "\n",
        "#given a list of samples, make a copy of each sample but more blurred to simulate objects out of focus, dirty lenses, and backscattering\n",
        "def blurAugment(samples):\n",
        "    out = []\n",
        "    for sample in samples:\n",
        "        image, label = sample\n",
        "        ksize = (20, 20) # lower to lower blur  \n",
        "        blurred_img = cv2.blur(image, ksize) \n",
        "        out.append((blurred_img, label))\n",
        "    samples.extend(out)\n",
        "    del out\n",
        "    del sample\n",
        "    return samples\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with a lower contrast image to simulate backscattering and over/under-exposure\n",
        "def contrastAugment(samples):\n",
        "    out = []\n",
        "    for sample in samples:\n",
        "        image, label = sample\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=0, contrast=(0.3, 0.3), saturation=0, hue=0, always_apply=True) ])\n",
        "        decontrasted_img = transform(image=image)[\"image\"]\n",
        "        out.append((decontrasted_img, label))\n",
        "    samples.extend(out)\n",
        "    del out\n",
        "    del transform\n",
        "    del sample\n",
        "    return samples\n",
        "    \n",
        "#given a list of samples, make a copy of each sample but with camera noise added to the image to simulate different camera feeds\n",
        "def noiseAugment(samples):\n",
        "    out = []\n",
        "    for sample in samples:\n",
        "        image, label = sample\n",
        "        transform = A.Compose([ A.augmentations.transforms.ISONoise(color_shift=(0.01, 0.01), intensity=(0.8, 0.8), always_apply=True) ])\n",
        "        noisy_img = transform(image=image)[\"image\"]\n",
        "        out.append((noisy_img, label))\n",
        "    samples.extend(out)\n",
        "    del out\n",
        "    del transform\n",
        "    del sample\n",
        "    return samples\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with the image downscaled (lower resolution of image) to simulate lower quality cameras/images\n",
        "def resolutionAugment(samples):\n",
        "    out = []\n",
        "    for sample in samples:\n",
        "        image, label = sample\n",
        "        #interpolation=A.augmentations.transforms.Interpolation(downscale=cv2.INTER_NEAREST, upscale=cv2.INTER_NEAREST)\n",
        "        transform = A.Compose([ A.augmentations.transforms.Downscale(scale_min=0.25, scale_max=0.25, always_apply=True) ])\n",
        "        low_res_img = transform(image=image)[\"image\"]\n",
        "        out.append((low_res_img, label))\n",
        "    samples.extend(out)\n",
        "    del out\n",
        "    del transform\n",
        "    del sample\n",
        "    return samples\n",
        "\n",
        "#increase intensity of blues in given image\n",
        "def make_bluer(img, color_shift_intensity):\n",
        "    img_b, img_g, img_r = cv2.split(img) #split by channel\n",
        "    img_b = np.uint16(img_b)\n",
        "    img_b += color_shift_intensity\n",
        "    np.clip(img_b, 0, 255, out=img_b)\n",
        "    img_b = np.uint8(img_b)\n",
        "    img = cv2.merge((img_b, img_g, img_r)) #merge adjusted channels\n",
        "    del img_b\n",
        "    del img_g\n",
        "    del img_r\n",
        "    return img\n",
        "\n",
        "#increase intensity of greens in given image\n",
        "def make_greener(img, color_shift_intensity):\n",
        "    img_b, img_g, img_r = cv2.split(img) #split by channel\n",
        "    img_g = np.uint16(img_g)\n",
        "    img_g += color_shift_intensity\n",
        "    np.clip(img_g, 0, 255, out=img_g)\n",
        "    img_g = np.uint8(img_g)\n",
        "    img = cv2.merge((img_b, img_g, img_r)) #merge adjusted channels\n",
        "    del img_b\n",
        "    del img_g\n",
        "    del img_r\n",
        "    return img\n",
        "\n",
        "#given a list of samples, make two copies of each sample (one bluer, one greener) to simulate different pools + color attenuation\n",
        "def colorAugment(samples):\n",
        "    out = []\n",
        "    color_shift_intensity = int(255*0.1)\n",
        "    for sample in samples:\n",
        "        image, label = sample\n",
        "        blue_img = make_bluer(image, color_shift_intensity)\n",
        "        green_img = make_greener(image, color_shift_intensity)\n",
        "        out.append((blue_img, label))\n",
        "        out.append((green_img, label))\n",
        "    samples.extend(out)\n",
        "    del out\n",
        "    del sample\n",
        "    return samples\n",
        "\n",
        "#remove all files/folders in folder\n",
        "def clearFolder(folder):\n",
        "    #get all directory/filenames in folder\n",
        "    for filename in os.listdir(folder):\n",
        "        file_path = os.path.join(folder, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                #delete all files\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                #recursively delete everything in sub-folders\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "#output given samples to given folder so that each image has corresponding label with same filename in /images and /labels subfolders respectively\n",
        "def sendToFolders(samples, output_folder):\n",
        "    #remove all files/folders in output folders\n",
        "    clearFolder(output_folder + \"/images\")\n",
        "    clearFolder(output_folder + \"/labels\")\n",
        "    instance_count = 0 #keep track of instance count for filename\n",
        "    for sample in samples:\n",
        "        image, label = sample\n",
        "        #write image to file in /images\n",
        "        cv2.imwrite(output_folder + '/images/img' + str(instance_count) + '.png', image)\n",
        "        #write label to file in /labels\n",
        "        with open(output_folder + '/labels/img' + str(instance_count) + '.txt', 'w+') as f:\n",
        "            #each box gets its own line\n",
        "            for box in label:\n",
        "                f.write(box)\n",
        "        instance_count += 1\n",
        "\n",
        "#given array of image/label arrays, and an integer of how to split the data, returns the dataset split accordingly\n",
        "def splitData(samples, splits):\n",
        "    #for now we just shuffle the data to hopefully get a similar similar sample size\n",
        "    # of images for every class in the train, test and val splits\n",
        "    #ideally in the future we should split by class and then combine together to make sure the datasets are balanced\n",
        "\n",
        "    #shuffle data\n",
        "    random.shuffle(samples)\n",
        "    #get indices for split\n",
        "    splits = [int(len(samples)*s) for s in splits]\n",
        "    #return split data\n",
        "    return samples[:splits[0]], samples[splits[0]:splits[0]+splits[1]], samples[splits[0]+splits[1]:]\n",
        "\n",
        "#given a single image and augmentation function, displays the image before and images after augmentation\n",
        "def visualizeAugmentation(img, aug):\n",
        "    #show original image\n",
        "    cv2.imshow('og', img)\n",
        "    cv2.waitKey(0)\n",
        "    #show all augmented images\n",
        "    for augmented in aug([(img, \"\")])[1:]:\n",
        "        cv2.imshow('augmented',augmented[0])\n",
        "        cv2.waitKey(0)\n",
        "\n",
        "#given source dataset folder, loads all images and labels into arrays\n",
        "def loadInputData(source_folder):\n",
        "    samples = []\n",
        "    #get all filenames in the /images subfolder of given source_folder\n",
        "    img_filenames = [f for f in listdir(source_folder + '/images') if isfile(join(source_folder + '/images', f))]\n",
        "    for img_filename in img_filenames:\n",
        "        #load image at that filename\n",
        "        img = cv2.imread(source_folder + '/images/' + img_filename)\n",
        "        #got label filename corresponding to the image\n",
        "        label_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
        "        #load in the label file contents\n",
        "        with open(source_folder + \"/labels/\" + label_filename) as f:\n",
        "            #build array of bounding boxes (each line its own element)\n",
        "            bounding_boxes = []\n",
        "            for line in f.read().split(\"\\n\"):\n",
        "                bounding_boxes.append(line)\n",
        "        #add image and label to sample set\n",
        "        samples.append( (img, bounding_boxes) )\n",
        "    del img_filenames\n",
        "    return samples\n"
      ],
      "metadata": {
        "id": "ffYKzEDIz225"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in all files from /raw folder, pass list of images sequentially through each augmentation function, then output final images to /augmented folder"
      ],
      "metadata": {
        "id": "NY5fTW4G02T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_val_split = (0.7, 0.2, 0.1)\n",
        "out_folder = \"data/augmented\"\n",
        "in_folder = \"data/raw\"\n",
        "\n",
        "print(\"Loading data...\")\n",
        "data = loadInputData(in_folder)\n",
        "\n",
        "#FOR TESTING uncomment to visualize individual augmentations\n",
        "#visualizeAugmentation(data[0][0], colorAugment)\n",
        "#exit()\n",
        "\n",
        "#order of augmentations should be optimized so that slower augmentations are done first\n",
        "#print(\"Augmenting noise...\")\n",
        "#data = noiseAugment(data) # times 2\n",
        "#print(\"Augmenting resolution...\")\n",
        "#data = resolutionAugment(data) # times 2\n",
        "print(\"Augmenting color...\")\n",
        "data = colorAugment(data) # times 3\n",
        "print(\"Augmenting brightness...\")\n",
        "data = brightnessAugment(data) # times 3\n",
        "print(\"Augmenting contrast...\")\n",
        "data = contrastAugment(data) # times 2\n",
        "#print(\"Augmenting blur...\")\n",
        "#data = blurAugment(data) # times 2\n",
        "print(\"Splitting data...\")\n",
        "train, test, val = splitData(data, train_test_val_split)\n",
        "print(\"Exporting training data...\")\n",
        "sendToFolders(train, out_folder + \"/train\")\n",
        "print(\"Exporting test data...\")\n",
        "sendToFolders(test, out_folder + \"/test\")\n",
        "print(\"Exporting val data...\")\n",
        "sendToFolders(val, out_folder + \"/val\")\n",
        "print(\"Done. Final number of samples: \" + str(len(data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uByRW0J20W8e",
        "outputId": "ac757495-0e67-4a91-9286-a4030da992a9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Augmenting color...\n",
            "Augmenting brightness...\n",
            "Augmenting contrast...\n",
            "Splitting data...\n",
            "Exporting training data...\n",
            "Exporting test data...\n",
            "Exporting val data...\n",
            "Done. Final number of samples: 954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train YOLO model with augmented data"
      ],
      "metadata": {
        "id": "Ha6R_QiX1mrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "#Ensure this prints true and a number > 0, if not make sure you set hardware accelerator to GPU in Edit > Notebook Settings > Hardware Accelerator\n",
        "!rm -r runs/detect/train*\n",
        "!mkdir runs\n",
        "!mkdir runs/detect\n",
        "!mkdir runs/detect/train"
      ],
      "metadata": {
        "id": "aZBXU0OD7l9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
        "# Train the model in increments\n",
        "epoch_increments = 10\n",
        "i = 2\n",
        "while True:\n",
        "  model.train(data=\"data.yaml\", epochs=epoch_increments, device=0, batch=16, degrees=360, flipud=0.5, fliplr=0.5, perspective=0.001, translate=0.5, scale=0.5, pretrained=True, task='detect')  # train the model\n",
        "  model.val()\n",
        "  shutil.copyfile(\"runs/detect/train\" + str(i) + \"/weights/best.pt\", \"/content/drive/My Drive/AUV_model_\" + str(i) + \".pt\")\n",
        "  i = i + 1"
      ],
      "metadata": {
        "id": "w1a82eTY1rFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb804030-251b-4eb1-9eab-c17a23dc5eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.47 ðŸš€ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, min_memory=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=360, translate=0.5, scale=0.5, shear=0.0, perspective=0.001, flipud=0.5, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.Detect                [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/augmented/train/labels.cache... 667 images, 73 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 667/667 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/augmented/val/labels.cache... 97 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/10      2.28G      2.144      4.833      2.275         14        640:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 23/42 [00:33<00:18,  1.05it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict on image with model"
      ],
      "metadata": {
        "id": "b6Tpx-d_3Mj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"data/augmented/train/images/img3.png\"\n",
        "img = cv2.imread(img_path)\n",
        "# Load a model\n",
        "model = YOLO(\"runs/detect/train2/weights/best.pt\")  # load a model\n",
        "# Use the model\n",
        "pred = model(img)\n",
        "for results in pred:\n",
        "    box = results.boxes\n",
        "    print(box)\n",
        "    print(\"\\nprediction:\" + str(list(box.xywh)))\n",
        "    print(\"\\nprediction:\" + str(list(box.conf)))\n",
        "    print(\"\\nprediction:\" + str(list(box.cls)))"
      ],
      "metadata": {
        "id": "UdXmFvGW3Q8J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}