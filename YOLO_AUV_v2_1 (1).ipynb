{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DEFINE PARAMETERS (this is the only thing to modify if you just want to train a model)"
      ],
      "metadata": {
        "id": "LkA2uszFgZdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Roboflow parameters\n",
        "roboflow_api_key = \"MJQUATZvpcKoBxRjLuXx\"\n",
        "roboflow_workspace_name = \"auv2024\"\n",
        "roboflow_project_name = \"auv-frontcam-visionv2\"\n",
        "roboflow_project_version = 1\n",
        "\n",
        "# Training parameters\n",
        "target_classes = [\"Buoy\", \"Gate\", \"Lane Marker\", \"underwater\"]\n",
        "train_test_val_split = (0.7, 0.2, 0.1)\n",
        "model_save_filename = \"best_AUV_sim_front_cam_model.pt\"\n",
        "epoch_increments = 1 # save the model weights to google drive every `epoch_increments` epochs\n",
        "batch_size = 16\n",
        "\n",
        "# Custom augmentation parameters\n",
        "colorAugmentProb = 0.5\n",
        "noiseAugmentProb = 0.5\n",
        "resolutionAugmentProb = 0.5\n",
        "contrastAugmentProb = 0.5\n",
        "blurAugmentProb = 0.5\n",
        "brightnessAugmentProb = 0.0\n",
        "\n",
        "# WARNING: do not change these \"randomly\", check the YoloV8 docs for what these parameters affect before modifying (these values have worked well)\n",
        "# See the last cell for where these parameters are used in the model\n",
        "degrees = 360\n",
        "flipud = 0.5\n",
        "fliplr = 0.5\n",
        "max_perspective_change = 0.001\n",
        "max_translate = 0.1\n",
        "max_scale_change = 0.3\n",
        "mosaic = 0.5\n",
        "mixup = 0.5"
      ],
      "metadata": {
        "id": "tZTwtOPQgY3A"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPLEMENTATION"
      ],
      "metadata": {
        "id": "MTYLP5gRgelD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Drive, setup Python dependencies"
      ],
      "metadata": {
        "id": "et9kLMSDbkvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma-GR0Q5Qn4k",
        "outputId": "a578908d-0607-427d-ede0-3b78e673c584"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58F4m91jwxYX",
        "outputId": "4d447798-d9e4-4fdc-8c06-a11992ed3133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.25)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.50.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.8.0.74)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.10.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (24.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.1.32)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.10.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.4.99)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cycler>=0.10->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "mkdir: cannot create directory â€˜dataâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmentedâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/trainâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/testâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/valâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/train/imagesâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/test/imagesâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/val/imagesâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/train/labelsâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/test/labelsâ€™: File exists\n",
            "mkdir: cannot create directory â€˜data/augmented/val/labelsâ€™: File exists\n",
            "rm: cannot remove 'sample_data': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "!pip install albumentations\n",
        "!pip install opencv-python\n",
        "!pip install ultralytics\n",
        "\n",
        "!mkdir data\n",
        "!mkdir data/augmented\n",
        "!mkdir data/augmented/train\n",
        "!mkdir data/augmented/test\n",
        "!mkdir data/augmented/val\n",
        "!mkdir data/augmented/train/images\n",
        "!mkdir data/augmented/test/images\n",
        "!mkdir data/augmented/val/images\n",
        "!mkdir data/augmented/train/labels\n",
        "!mkdir data/augmented/test/labels\n",
        "!mkdir data/augmented/val/labels\n",
        "!rm -r sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "sN29TW2MxhB9"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "from roboflow import Roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define YOLO classes"
      ],
      "metadata": {
        "id": "CVo9YblEb93v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "M03OBN22xr4s"
      },
      "outputs": [],
      "source": [
        "with open('data.yaml', 'w+') as f:\n",
        "    f.write(\"train: /content/data/augmented/train/images\\n\")\n",
        "    f.write(\"test: /content/data/augmented/test/images\\n\")\n",
        "    f.write(\"val: /content/data/augmented/val/images\\n\")\n",
        "    f.write(\"nc: {}\\n\".format(len(target_classes)))\n",
        "    f.write('names: {}'.format(target_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define augmentation functions"
      ],
      "metadata": {
        "id": "Yf6GvElFcDgY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "PRAkj-Gzxu0m"
      },
      "outputs": [],
      "source": [
        "#given a list of samples, make two copies of each sample that are darker/brighter to simulate differently lit environments\n",
        "def brightnessAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=(1.05, 1.05), contrast=0, saturation=0, hue=0, always_apply=True) ])\n",
        "        bright_img = transform(image=image)[\"image\"]\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=(0.95, 0.95), contrast=0, saturation=0, hue=0, always_apply=True) ])\n",
        "        dark_img = transform(image=image)[\"image\"]\n",
        "        out.append(bright_img)\n",
        "        out.append(dark_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but more blurred to simulate objects out of focus, dirty lenses, and backscattering\n",
        "def blurAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        ksize = (10, 10) # lower to lower blur\n",
        "        blurred_img = cv2.blur(image, ksize)\n",
        "        out.append(blurred_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with a lower contrast image to simulate backscattering and over/under-exposure\n",
        "def contrastAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=0, contrast=(0.1, 0.1), saturation=0, hue=0, always_apply=True) ])\n",
        "        decontrasted_img = transform(image=image)[\"image\"]\n",
        "        out.append(decontrasted_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with camera noise added to the image to simulate different camera feeds\n",
        "def noiseAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        transform = A.Compose([ A.augmentations.transforms.ISONoise(color_shift=(0.01, 0.01), intensity=(0.8, 0.8), always_apply=True) ])\n",
        "        noisy_img = transform(image=image)[\"image\"]\n",
        "        out.append(noisy_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with the image downscaled (lower resolution of image) to simulate lower quality cameras/images\n",
        "def resolutionAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        #interpolation=A.augmentations.transforms.Interpolation(downscale=cv2.INTER_NEAREST, upscale=cv2.INTER_NEAREST)\n",
        "        transform = A.Compose([ A.augmentations.transforms.Downscale(scale_min=0.25, scale_max=0.25, always_apply=True) ])\n",
        "        low_res_img = transform(image=image)[\"image\"]\n",
        "        out.append(low_res_img)\n",
        "    return out\n",
        "\n",
        "#increase intensity of blues in given image\n",
        "def make_bluer(img, color_shift_intensity):\n",
        "    img_b, img_g, img_r = cv2.split(img) #split by channel\n",
        "    img_b = np.uint16(img_b)\n",
        "    img_b += color_shift_intensity\n",
        "    np.clip(img_b, 0, 255, out=img_b)\n",
        "    img_b = np.uint8(img_b)\n",
        "    img = cv2.merge((img_b, img_g, img_r)) #merge adjusted channels\n",
        "    del img_b\n",
        "    del img_g\n",
        "    del img_r\n",
        "    return img\n",
        "\n",
        "#increase intensity of greens in given image\n",
        "def make_greener(img, color_shift_intensity):\n",
        "    img_b, img_g, img_r = cv2.split(img) #split by channel\n",
        "    img_g = np.uint16(img_g)\n",
        "    img_g += color_shift_intensity\n",
        "    np.clip(img_g, 0, 255, out=img_g)\n",
        "    img_g = np.uint8(img_g)\n",
        "    img = cv2.merge((img_b, img_g, img_r)) #merge adjusted channels\n",
        "    del img_b\n",
        "    del img_g\n",
        "    del img_r\n",
        "    return img\n",
        "\n",
        "#given a list of samples, make two copies of each sample (one bluer, one greener) to simulate different pools + color attenuation\n",
        "def colorAugment(images):\n",
        "    out = []\n",
        "    color_shift_intensity = int(255*0.1)\n",
        "    for image in images:\n",
        "        blue_img = make_bluer(image, color_shift_intensity)\n",
        "        green_img = make_greener(image, color_shift_intensity)\n",
        "        out.append(blue_img)\n",
        "        out.append(green_img)\n",
        "    return out\n",
        "\n",
        "#given a single image and augmentation function, displays the image before and images after augmentation\n",
        "def visualizeAugmentation(img, aug):\n",
        "    #show original image\n",
        "    cv2.imshow('og', img)\n",
        "    cv2.waitKey(0)\n",
        "    #show all augmented images\n",
        "    for augmented in aug([(img, \"\")])[1:]:\n",
        "        cv2.imshow('augmented',augmented[0])\n",
        "        cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "o94FDfOVyBvu"
      },
      "outputs": [],
      "source": [
        "def get_file_names(source_folder):\n",
        "    label_filenames = []\n",
        "    img_filenames = [f for f in listdir(source_folder + '/images') if isfile(join(source_folder + '/images', f))]\n",
        "    for img_filename in img_filenames:\n",
        "        label_filenames.append(os.path.splitext(img_filename)[0] + \".txt\")\n",
        "\n",
        "    return np.array(img_filenames), np.array(label_filenames)\n",
        "\n",
        "def split_file_names(images,labels,splits):\n",
        "    perm = np.random.permutation(len(images))\n",
        "    images = images[perm]\n",
        "    labels = labels[perm]\n",
        "    splits = [int(len(images)*s) for s in splits]\n",
        "    train_images = images[:splits[0]]\n",
        "    train_labels = labels[:splits[0]]\n",
        "    val_images = images[splits[0]: splits[0] + splits[1]]\n",
        "    val_labels = labels[splits[0]: splits[0] + splits[1]]\n",
        "    test_images = images[splits[0] + splits[1]:]\n",
        "    test_labels = labels[splits[0] + splits[1]:]\n",
        "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
        "\n",
        "def get_augs(img_filename,source_folder):\n",
        "    img = cv2.imread(source_folder + '/images/' + img_filename)\n",
        "    augs = [img]\n",
        "    if(np.random.rand() < colorAugmentProb):\n",
        "        augs = augs + colorAugment(augs)\n",
        "    if(np.random.rand() < noiseAugmentProb):\n",
        "        augs = augs + noiseAugment(augs)\n",
        "    if(np.random.rand() < resolutionAugmentProb):\n",
        "        augs = augs + resolutionAugment(augs)\n",
        "    if(np.random.rand() < contrastAugmentProb):\n",
        "        augs = augs + contrastAugment(augs)\n",
        "    if(np.random.rand() < blurAugmentProb):\n",
        "        augs = augs + blurAugment(augs)\n",
        "    if(np.random.rand() < brightnessAugmentProb):\n",
        "        augs = augs + brightnessAugment(augs)\n",
        "    return augs\n",
        "\n",
        "def do_augs_and_export(img_filenames,label_filenames,source_folder,output_folder):\n",
        "    name_num = 1\n",
        "    for (img_filename,label_filename) in zip(img_filenames,label_filenames):\n",
        "        augs = get_augs(img_filename,source_folder)\n",
        "        with open(source_folder + \"/labels/\" + label_filename) as f:\n",
        "            #build array of bounding boxes (each line its own element)\n",
        "            bounding_boxes = f.read()\n",
        "        for aug in augs:\n",
        "            cv2.imwrite(output_folder + '/images/img' + str(name_num) + '.png', aug)\n",
        "            with open(output_folder + '/labels/img' + str(name_num) + '.txt',\"w+\") as f:\n",
        "                f.write(bounding_boxes)\n",
        "            name_num+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset from RoboFlow"
      ],
      "metadata": {
        "id": "3gg8L31ZcdXv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p69--bQOySln",
        "outputId": "ffe7b28f-1597-47f5-81b2-2fb201f3b6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in auv-frontcam-visionv2-1 to yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2842/2842 [00:01<00:00, 2000.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to auv-frontcam-visionv2-1 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 8572.49it/s]\n"
          ]
        }
      ],
      "source": [
        "rf = Roboflow(api_key=roboflow_api_key)\n",
        "project = rf.workspace(roboflow_workspace_name).project(roboflow_project_name)\n",
        "version = project.version(roboflow_project_version)\n",
        "dataset = version.download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "e2wDV0S-z5ft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f107caf2-e216-4036-8a27-7e1452d59cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auv-frontcam-visionv2-1\n",
            "mv: cannot stat '/content/auv-frontcam-visionv2-1/train/': No such file or directory\n",
            "mv: cannot stat '/content/auv-frontcam-visionv2-1/test/images/*': No such file or directory\n",
            "mv: cannot stat '/content/auv-frontcam-visionv2-1/valid/images/*': No such file or directory\n",
            "mv: cannot stat '/content/auv-frontcam-visionv2-1/test/labels/*': No such file or directory\n",
            "mv: cannot stat '/content/auv-frontcam-visionv2-1/valid/labels/*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "folder_name = \"{}-{}\".format(roboflow_project_name, roboflow_project_version)\n",
        "\n",
        "print(folder_name)\n",
        "\n",
        "!mv /content/$folder_name/train/ /content/data/raw\n",
        "!mv /content/$folder_name/test/images/* /content/data/raw/images/\n",
        "!mv /content/$folder_name/valid/images/* /content/data/raw/images/\n",
        "!mv /content/$folder_name/test/labels/* /content/data/raw/labels/\n",
        "!mv /content/$folder_name/valid/labels/* /content/data/raw/labels/\n",
        "!rm -r $folder_name"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augment data, split into train/test/val"
      ],
      "metadata": {
        "id": "s3uZyY_uer3H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Pkd3wksY0k2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d9893a-9e5d-4310-fde2-6ddf8f8c9e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmentation completed. Went from 134 raw samples to a total of 1517 after augmentation.\n"
          ]
        }
      ],
      "source": [
        "out_folder = \"data/augmented\"\n",
        "in_folder = \"data/raw\"\n",
        "\n",
        "img_names, label_names = get_file_names(in_folder)\n",
        "num_raw_samples = len(img_names)\n",
        "train_images, train_labels, val_images, val_labels, test_images, test_labels = split_file_names(img_names,label_names,train_test_val_split)\n",
        "do_augs_and_export(train_images,train_labels,in_folder,out_folder + \"/train\")\n",
        "do_augs_and_export(val_images,val_labels,in_folder,out_folder + \"/val\")\n",
        "do_augs_and_export(test_images,test_labels,in_folder,out_folder + \"/test\")\n",
        "\n",
        "augmented_train_img_names, _ = get_file_names(out_folder + \"/train\")\n",
        "augmented_test_img_names, _ = get_file_names(out_folder + \"/test\")\n",
        "augmented_val_img_names, _ = get_file_names(out_folder + \"/val\")\n",
        "\n",
        "num_augmented_samples = len(augmented_train_img_names) + len(augmented_test_img_names) + len(augmented_val_img_names)\n",
        "\n",
        "print(\"Augmentation completed. Went from {} raw samples to a total of {} after augmentation.\".format(num_raw_samples, num_augmented_samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check CUDA dependencies and start training"
      ],
      "metadata": {
        "id": "mpkZGNqWgQ7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "0AotbSTe2pLU"
      },
      "outputs": [],
      "source": [
        "CUDA_setup_is_valid = torch.cuda.is_available() and torch.cuda.device_count() > 0\n",
        "\n",
        "if not CUDA_setup_is_valid:\n",
        "  raise Exception('No CUDA device detected. Make sure you set hardware accelerator to GPU in Edit > Notebook Settings > Hardware Accelerator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9JgHc3R3950",
        "outputId": "80569dde-71a0-489b-bbfc-d627c84d2fda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜runsâ€™: File exists\n",
            "mkdir: cannot create directory â€˜runs/detectâ€™: File exists\n",
            "Ultralytics YOLOv8.1.32 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Caught a RuntimeError: CUDA error: device-side assert triggered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!rm -r runs/detect/train*\n",
        "!mkdir runs\n",
        "!mkdir runs/detect\n",
        "!mkdir runs/detect/train\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\") #load a pretrained model\n",
        "\n",
        "# Start the training process\n",
        "while True:\n",
        "    try:\n",
        "        model.train(\n",
        "            data=\"data.yaml\",\n",
        "            epochs=epoch_increments,\n",
        "            device=0,\n",
        "            batch=batch_size,\n",
        "            degrees=degrees,\n",
        "            flipud=flipud,\n",
        "            fliplr=fliplr,\n",
        "            perspective=max_perspective_change,\n",
        "            translate=max_translate,\n",
        "            scale=max_scale_change,\n",
        "            mosaic=mosaic,\n",
        "            mixup=mixup,\n",
        "            pretrained=True,\n",
        "            task='detect',\n",
        "        )\n",
        "        shutil.copyfile(\"runs/detect/train/weights/best.pt\", \"/content/drive/My Drive/{}\".format(model_save_filename))\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Caught a RuntimeError: {e}\")\n",
        "        break  # Break out of the loop if an error occurs to prevent infinite loop\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "Yf6GvElFcDgY"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}